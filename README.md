# NICE: Neural Intelligence for Compound legal rEasoning

**åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ³•å¾‹å·¥ä½œæµè‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

NICE æ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ³•å¾‹AIç³»ç»Ÿï¼Œèåˆäº† **AFlow**ï¼ˆå·¥ä½œæµæ¡†æ¶ï¼‰å’Œ **ROLL**ï¼ˆå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼‰ï¼Œé€šè¿‡è®­ç»ƒå°æ¨¡å‹ç”Ÿæˆå·¥ä½œæµä»£ç æ¥è°ƒåº¦å¤§æ¨¡å‹æ‰§è¡Œå¤æ‚æ³•å¾‹æ¨ç†ä»»åŠ¡ã€‚

### æ ¸å¿ƒæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              NICE ç³»ç»Ÿæ¶æ„                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Qwen2.5-7B      â”‚ ç”Ÿæˆ    â”‚   Workflow Code  â”‚ æ‰§è¡Œ    â”‚ GPT-4o-   â”‚  â”‚
â”‚   â”‚  + LoRA          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (Pythonç±»)     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ mini      â”‚  â”‚
â”‚   â”‚  (å°æ¨¡å‹)         â”‚         â”‚                  â”‚         â”‚ (å¤§æ¨¡å‹)   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚                                                       â”‚        â”‚
â”‚            â”‚  GRPOä¼˜åŒ–                              å¥–åŠ±åé¦ˆ        â”‚        â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒåˆ›æ–°

- **åŒæ¨¡å‹åä½œ**ï¼šå°æ¨¡å‹å­¦ä¹ "å¦‚ä½•ç»„ç»‡å·¥ä½œæµ"ï¼Œå¤§æ¨¡å‹è´Ÿè´£"å®é™…æ¨ç†æ‰§è¡Œ"
- **WA-GRPOç®—æ³•**ï¼šWorkflow-Aware GRPOï¼Œè§£å†³ç»„å†…åŒåˆ†çš„å…¨é›¶ä¼˜åŠ¿é—®é¢˜
- **æ³•å¾‹åŒç³»ç»Ÿæ”¯æŒ**ï¼šä¸­å›½æ³•å¾‹ï¼ˆå¤§é™†æ³•ç³»ï¼‰+ ç¾å›½æ³•å¾‹ï¼ˆæ™®é€šæ³•ç³»ï¼‰
- **6ä¸ªæ³•å¾‹ä¸“ç”¨Operator**ï¼šé’ˆå¯¹æ³•å¾‹æ¨ç†ä»»åŠ¡è®¾è®¡çš„ä¸“ä¸šç®—å­

---

## ğŸ›ï¸ æ³•å¾‹æ¨¡å—

### æ”¯æŒçš„æ³•å¾‹ä½“ç³»

| ä½“ç³» | ç‰¹ç‚¹ | æ•°æ®æº |
|------|------|--------|
| ğŸ‡¨ğŸ‡³ ä¸­å›½æ³•å¾‹ | æˆæ–‡æ³•ä¸ºä¸»ï¼Œå¸æ³•è§£é‡Šè¡¥å…… | CAIL2018, DISC-Law-SFT |
| ğŸ‡ºğŸ‡¸ ç¾å›½æ³•å¾‹ | åˆ¤ä¾‹æ³•ä¸ºä¸»ï¼Œéµå¾ªå…ˆä¾‹åŸåˆ™ | LegalBench, CaseHOLD |

### æ³•å¾‹Operator

| Operator | åŠŸèƒ½ | ä¸­å›½ç‰¹è‰² | ç¾å›½ç‰¹è‰² |
|----------|------|----------|----------|
| `DirectAnswer` | ç›´æ¥ç”Ÿæˆæ³•å¾‹ç­”æ¡ˆ | - | - |
| `CaseLearning` | æ¡ˆä¾‹æ£€ç´¢å­¦ä¹  | æŒ‡å¯¼æ€§æ¡ˆä¾‹ã€å…¸å‹æ¡ˆä¾‹ | Binding/Persuasive precedents |
| `StatuteLearning` | æ³•æ¡æ£€ç´¢å­¦ä¹  | åˆ‘æ³•/æ°‘æ³•å…¸ + å¸æ³•è§£é‡Š | U.S. Code + CFR |
| `Debate` | å¤šè§’è‰²è¾©è®º | åŸå‘Š/è¢«å‘Š/æ³•å®˜è§†è§’ | åŒå·¦ |
| `LegalEnsemble` | é›†æˆé€‰æ‹© | å¤šç­”æ¡ˆæŠ•ç¥¨é€‰ä¼˜ | åŒå·¦ |
| `LegalRevise` | æ³•å¾‹ä¿®è®¢ | æ£€æŸ¥ç½ªåè¡¨è¿°è§„èŒƒ | æ£€æŸ¥Bluebookå¼•ç”¨æ ¼å¼ |

### æ³•å¾‹Workflowç¤ºä¾‹

```python
class Workflow:
    def __init__(self, name, llm_config, dataset):
        self.retriever = LegalRetriever(data_dir="data/legal")
        self.case_learning = CaseLearning(self.llm, self.retriever)
        self.statute_learning = StatuteLearning(self.llm, self.retriever)
        self.debate = Debate(self.llm)
        self.legal_revise = LegalRevise(self.llm)

    async def __call__(self, problem: str):
        # 1. æ¡ˆä¾‹å­¦ä¹  - æ£€ç´¢ç›¸å…³åˆ¤ä¾‹
        case_result = await self.case_learning(
            question=problem, jurisdiction="CN", top_k=3
        )

        # 2. æ³•æ¡å­¦ä¹  - æ£€ç´¢é€‚ç”¨æ³•æ¡
        statute_result = await self.statute_learning(
            question=problem, jurisdiction="CN"
        )

        # 3. æ•´åˆä¸Šä¸‹æ–‡
        context = f"{case_result['learning_record']}\n{statute_result['learning_record']}"

        # 4. å¤šè§’è‰²è¾©è®º
        debate_result = await self.debate(
            question=problem, context=context, jurisdiction="CN"
        )

        # 5. æ³•å¾‹ä¿®è®¢æ£€æŸ¥
        final = await self.legal_revise(
            answer=debate_result['final_answer'], question=problem
        )

        return final['revised_answer'], self.llm.get_usage_summary()["total_cost"]
```

---

## ğŸ”¬ ç®—æ³•è¯¦è§£

### GRPO (Group Relative Policy Optimization)

```python
# å¯¹æ¯ä¸ªé—®é¢˜ç”Ÿæˆ K=4 ä¸ªå·¥ä½œæµ
for problem in batch:
    workflows = model.generate(problem, num_return_sequences=4)
    rewards = [execute_and_evaluate(w) for w in workflows]

    # ç»„å†…å½’ä¸€åŒ–ï¼ˆæ ¸å¿ƒæ€æƒ³ï¼‰
    advantages = (rewards - mean(rewards)) / std(rewards)

    # PPO-style ç­–ç•¥æ›´æ–°
    loss = -min(ratio * adv, clip(ratio, 0.8, 1.2) * adv)
```

### WA-GRPO æ”¹è¿›

è§£å†³ GRPO çš„ã€Œå…¨é›¶ä¼˜åŠ¿ã€é—®é¢˜ï¼šå½“ç»„å†…æ‰€æœ‰å›ç­”å¥–åŠ±ç›¸åŒæ—¶ï¼Œæ ‡å‡†GRPOæ— æ³•å­¦ä¹ ã€‚

```python
# WA-GRPO: ä½¿ç”¨ workflow ç‰¹å¾ä½œä¸º tie-breaker
if std(rewards) < threshold:
    tie_breaker = (
        0.35 * diversity_score +      # ä»£ç å¤šæ ·æ€§
        0.25 * revise_gain +          # Reviseæ”¹è¿›å¹…åº¦
        0.20 * exec_success +         # æ‰§è¡ŒæˆåŠŸåº¦
        0.10 * efficiency +           # è¿è¡Œæ•ˆç‡
        0.10 * op_variety             # Operatorè¦†ç›–åº¦
    )
    rewards = rewards + alpha * tie_breaker  # alpha=0.12
```

### 5æ¡£å¥–åŠ±ç³»ç»Ÿ

```
å¥–åŠ±ç­‰çº§: [0.0, 0.2, 0.4, 0.7, 1.0]

è¯„ä¼°ç»´åº¦ï¼ˆæ³•å¾‹ä»»åŠ¡ï¼‰:
â”œâ”€â”€ legal_basis:   35%  # æ³•å¾‹ä¾æ®å‡†ç¡®æ€§
â”œâ”€â”€ reasoning:     25%  # æ¨ç†é€»è¾‘è´¨é‡
â”œâ”€â”€ conclusion:    20%  # ç»“è®ºæ­£ç¡®æ€§
â””â”€â”€ completeness:  20%  # ç­”æ¡ˆå®Œæ•´æ€§
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
nice-main/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ grpo_trainer.py           # GRPOè®­ç»ƒå™¨ä¸»ç±»
â”‚   â”œâ”€â”€ wa_grpo.py                # WA-GRPOä¼˜åŠ¿è®¡ç®—
â”‚   â”œâ”€â”€ rl_workflow_generator.py  # Qwen2.5-7Bå·¥ä½œæµç”Ÿæˆ
â”‚   â”œâ”€â”€ aflow_executor.py         # AFlowæ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ reward_computer.py        # 5æ¡£å¥–åŠ±è®¡ç®—
â”‚   â”œâ”€â”€ data_manager.py           # æ··åˆæ•°æ®é›†ç®¡ç†
â”‚   â”œâ”€â”€ workflow_validator.py     # å·¥ä½œæµä»£ç éªŒè¯
â”‚   â””â”€â”€ legal/                    # æ³•å¾‹æ¨¡å—
â”‚       â”œâ”€â”€ operators.py          # 6ä¸ªæ³•å¾‹Operator
â”‚       â”œâ”€â”€ retriever.py          # FAISSå‘é‡æ£€ç´¢
â”‚       â”œâ”€â”€ data_processor.py     # æ³•å¾‹æ•°æ®å¤„ç†
â”‚       â””â”€â”€ reward.py             # æ³•å¾‹å¥–åŠ±è®¡ç®—
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ training_legal.yaml       # æ³•å¾‹è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ aflow_llm.yaml            # OpenAI APIé…ç½®
â”œâ”€â”€ data/
â”‚   â””â”€â”€ legal/                    # æ³•å¾‹æ•°æ®é›†
â”‚       â”œâ”€â”€ cn/                   # ä¸­å›½æ³•å¾‹æ•°æ®
â”‚       â””â”€â”€ us/                   # ç¾å›½æ³•å¾‹æ•°æ®
â”œâ”€â”€ train.py                      # è®­ç»ƒå…¥å£
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_legal_module.py      # æ³•å¾‹æ¨¡å—æµ‹è¯•
â””â”€â”€ docs/                         # æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (æ¨è)
- æ˜¾å­˜ â‰¥ 24GB (ç”¨äºQwen2.5-7B)

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/beita6969/legal.git
cd legal

# å®‰è£…ä¾èµ–
pip install torch transformers peft accelerate
pip install faiss-cpu sentence-transformers  # æ³•å¾‹æ£€ç´¢
pip install openai wandb                      # APIå’Œç›‘æ§
```

### é…ç½®API

ç¼–è¾‘ `config/aflow_llm.yaml`:

```yaml
models:
  "gpt-4o-mini":
    api_type: "openai"
    base_url: "https://api.openai.com/v1"
    api_key: "YOUR_OPENAI_API_KEY"  # æ›¿æ¢ä¸ºä½ çš„API Key
    model: "gpt-4o-mini"
```

### å¯åŠ¨è®­ç»ƒ

```bash
# æ³•å¾‹é¢†åŸŸè®­ç»ƒ
python train.py --config config/training_legal.yaml

# ç›‘æ§è®­ç»ƒï¼ˆéœ€è¦wandbï¼‰
wandb login
python train.py --config config/training_legal.yaml
```

### æµ‹è¯•æ³•å¾‹æ¨¡å—

```bash
python tests/test_legal_module.py
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒé…ç½® (`config/training_legal.yaml`)

```yaml
# åŸºæœ¬é…ç½®
exp_name: "legal_grpo_cn_us_dual"
max_steps: 500
rollout_batch_size: 6
num_return_sequences_in_group: 4   # K=4 (GRPOç»„å¤§å°)

# æ³•å¾‹æ•°æ®æ¯”ä¾‹
domain_ratios:
  legal_cn: 0.5   # 50% ä¸­å›½æ³•å¾‹
  legal_us: 0.5   # 50% ç¾å›½æ³•å¾‹

# æ¨¡å‹é…ç½®
base_model: "Qwen/Qwen2.5-7B-Instruct"
lora_rank: 64
lora_alpha: 64

# WA-GRPOé…ç½®
wa_grpo:
  alpha: 0.12                # tie-breakerç³»æ•°
  diversity_weight: 0.35
  exec_success_weight: 0.20
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| `train/accuracy` | è®­ç»ƒé›†å‡†ç¡®ç‡ |
| `train/avg_reward` | å¹³å‡å¥–åŠ± (0-1) |
| `grpo/zero_advantage_ratio` | å…¨é›¶ä¼˜åŠ¿ç»„æ¯”ä¾‹ (è¶Šä½è¶Šå¥½) |
| `train/loss` | PPOæŸå¤± |
| `train/kl_div` | KLæ•£åº¦ |

---

## ğŸ“š å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{nice2024,
  title={NICE: Neural Intelligence for Compound legal rEasoning},
  author={Zhang Mingda},
  year={2024},
  url={https://github.com/beita6969/legal}
}
```

### ç›¸å…³å·¥ä½œ

- [AFlow](https://github.com/geekan/MetaGPT) - Workflowæ¡†æ¶
- [ROLL](https://github.com/alibaba/ROLL) - å¼ºåŒ–å­¦ä¹ æ¡†æ¶
- [GRPO](https://arxiv.org/abs/2402.03300) - DeepSeekçš„ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–

---

## ğŸ“„ License

MIT License - è¯¦è§ [LICENSE](LICENSE)

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStarï¼**
