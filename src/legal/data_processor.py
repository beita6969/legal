#!/usr/bin/env python3
"""
æ³•å¾‹æ•°æ®å¤„ç†å™¨ - æ•°æ®é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
Legal Data Processor - Data preprocessing and format conversion

æ”¯æŒ:
- CAIL2018 æ ¼å¼è½¬æ¢
- DISC-Law-SFT æ ¼å¼è½¬æ¢
- LegalBench æ ¼å¼è½¬æ¢
- è®­ç»ƒæ•°æ®ç”Ÿæˆ
"""

import json
import random
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict


class LegalDataProcessor:
    """æ³•å¾‹æ•°æ®å¤„ç†å™¨"""

    # ä»»åŠ¡ç±»å‹æ˜ å°„
    TASK_TYPE_MAP = {
        # ä¸­å›½æ•°æ®é›†
        'cail2018': 'case_prediction',
        'jec_qa': 'statute_qa',
        'disc_law': 'consultation',
        'refined_legal': 'case_prediction',
        # ç¾å›½æ•°æ®é›†
        'legalbench': 'statute_qa',
        'casehold': 'case_prediction',
        'cuad': 'document_gen'
    }

    def __init__(self, data_dir: str = "data/legal"):
        self.data_dir = Path(data_dir)

    def process_cail2018(
        self,
        input_file: str,
        output_file: str = None,
        max_samples: int = 5000
    ) -> List[Dict]:
        """
        å¤„ç†CAIL2018æ•°æ®é›†

        CAIL2018æ ¼å¼:
        {
            "fact": "ç»å®¡ç†æŸ¥æ˜...",
            "meta": {
                "accusation": ["ç›—çªƒ"],
                "relevant_articles": [264],
                "punish_of_money": 0,
                "criminals": ["å¼ ä¸‰"],
                "term_of_imprisonment": {...}
            }
        }
        """
        samples = []
        input_path = Path(input_file)

        if not input_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return samples

        print(f"ğŸ“– å¤„ç†CAIL2018æ•°æ®: {input_file}")

        with open(input_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= max_samples:
                    break

                if not line.strip():
                    continue

                try:
                    item = json.loads(line)
                    meta = item.get('meta', {})

                    # æ„å»ºground_truth
                    charges = meta.get('accusation', [])
                    articles = meta.get('relevant_articles', [])
                    term = meta.get('term_of_imprisonment', {})

                    # è®¡ç®—åˆ‘æœŸï¼ˆæœˆï¼‰
                    imprisonment_months = (
                        term.get('imprisonment', 0) +
                        term.get('death_penalty', 0) * 999 +
                        term.get('life_imprisonment', 0) * 999
                    )

                    sample = {
                        'id': f"cn_cail_{i}",
                        'jurisdiction': 'CN',
                        'problem': f"æ ¹æ®ä»¥ä¸‹æ¡ˆæƒ…äº‹å®ï¼Œåˆ†æè¢«å‘Šäººåº”å½“æ‰¿æ‹…çš„åˆ‘äº‹è´£ä»»ï¼š\n\n{item.get('fact', '')}",
                        'problem_type': 'legal',
                        'task_type': 'case_prediction',
                        'source': 'cail2018',
                        'ground_truth': {
                            'charges': charges,
                            'articles': [f"åˆ‘æ³•ç¬¬{a}æ¡" for a in articles],
                            'sentence': {
                                'imprisonment_months': imprisonment_months,
                                'fine': meta.get('punish_of_money', 0)
                            }
                        },
                        'legal_domain': 'criminal',
                        'difficulty': self._estimate_difficulty(item)
                    }
                    samples.append(sample)

                except json.JSONDecodeError as e:
                    print(f"âš ï¸  JSONè§£æé”™è¯¯ è¡Œ{i}: {e}")
                    continue

        print(f"âœ… å¤„ç†å®Œæˆ: {len(samples)} æ ·æœ¬")

        if output_file:
            self._save_jsonl(samples, output_file)

        return samples

    def process_disc_law(
        self,
        input_file: str,
        output_file: str = None,
        max_samples: int = 5000
    ) -> List[Dict]:
        """
        å¤„ç†DISC-Law-SFTæ•°æ®é›†

        DISCæ ¼å¼:
        {
            "input": "é—®é¢˜",
            "output": "ç­”æ¡ˆ",
            "type": "ç±»å‹"
        }
        """
        samples = []
        input_path = Path(input_file)

        if not input_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return samples

        print(f"ğŸ“– å¤„ç†DISC-Lawæ•°æ®: {input_file}")

        with open(input_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= max_samples:
                    break

                if not line.strip():
                    continue

                try:
                    item = json.loads(line)

                    # åˆ¤æ–­ä»»åŠ¡ç±»å‹
                    disc_type = item.get('type', 'qa')
                    if 'æ–‡ä¹¦' in disc_type or 'document' in disc_type.lower():
                        task_type = 'document_gen'
                    elif 'æ¡ˆä¾‹' in disc_type or 'case' in disc_type.lower():
                        task_type = 'case_prediction'
                    else:
                        task_type = 'consultation'

                    sample = {
                        'id': f"cn_disc_{i}",
                        'jurisdiction': 'CN',
                        'problem': item.get('input', ''),
                        'problem_type': 'legal',
                        'task_type': task_type,
                        'source': 'disc_law',
                        'ground_truth': {
                            'answer': item.get('output', '')
                        },
                        'legal_domain': self._detect_legal_domain(item.get('input', ''), 'CN'),
                        'difficulty': 'medium'
                    }
                    samples.append(sample)

                except json.JSONDecodeError:
                    continue

        print(f"âœ… å¤„ç†å®Œæˆ: {len(samples)} æ ·æœ¬")

        if output_file:
            self._save_jsonl(samples, output_file)

        return samples

    def process_legalbench(
        self,
        input_file: str,
        output_file: str = None,
        max_samples: int = 5000
    ) -> List[Dict]:
        """
        å¤„ç†LegalBenchæ•°æ®é›† (US)

        LegalBenchæ ¼å¼:
        {
            "text": "é—®é¢˜æ–‡æœ¬",
            "label": "æ ‡ç­¾/ç­”æ¡ˆ",
            "task": "ä»»åŠ¡åç§°"
        }
        """
        samples = []
        input_path = Path(input_file)

        if not input_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return samples

        print(f"ğŸ“– å¤„ç†LegalBenchæ•°æ®: {input_file}")

        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f) if input_file.endswith('.json') else [
                json.loads(line) for line in f if line.strip()
            ]

        for i, item in enumerate(data[:max_samples]):
            task_name = item.get('task', 'general')

            # æ˜ å°„ä»»åŠ¡ç±»å‹
            if 'contract' in task_name.lower():
                task_type = 'document_gen'
                legal_domain = 'contract'
            elif 'case' in task_name.lower() or 'holding' in task_name.lower():
                task_type = 'case_prediction'
                legal_domain = 'civil'
            else:
                task_type = 'statute_qa'
                legal_domain = self._detect_legal_domain(item.get('text', ''), 'US')

            sample = {
                'id': f"us_legalbench_{i}",
                'jurisdiction': 'US',
                'problem': item.get('text', item.get('question', '')),
                'problem_type': 'legal',
                'task_type': task_type,
                'source': 'legalbench',
                'ground_truth': {
                    'answer': str(item.get('label', item.get('answer', '')))
                },
                'legal_domain': legal_domain,
                'difficulty': 'medium',
                'original_task': task_name
            }
            samples.append(sample)

        print(f"âœ… å¤„ç†å®Œæˆ: {len(samples)} æ ·æœ¬")

        if output_file:
            self._save_jsonl(samples, output_file)

        return samples

    def process_casehold(
        self,
        input_file: str,
        output_file: str = None,
        max_samples: int = 5000
    ) -> List[Dict]:
        """
        å¤„ç†CaseHOLDæ•°æ®é›† (US)

        CaseHOLDæ ¼å¼:
        {
            "citing_prompt": "å¼•ç”¨ä¸Šä¸‹æ–‡",
            "holding_0": "é€‰é¡¹0",
            "holding_1": "é€‰é¡¹1",
            ...,
            "label": æ­£ç¡®é€‰é¡¹ç´¢å¼•
        }
        """
        samples = []
        input_path = Path(input_file)

        if not input_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return samples

        print(f"ğŸ“– å¤„ç†CaseHOLDæ•°æ®: {input_file}")

        with open(input_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= max_samples:
                    break

                if not line.strip():
                    continue

                try:
                    item = json.loads(line)

                    # æ„å»ºé—®é¢˜
                    prompt = item.get('citing_prompt', '')
                    holdings = [item.get(f'holding_{j}', '') for j in range(5)]
                    label = item.get('label', 0)

                    problem = f"{prompt}\n\nWhich holding is correct?\n"
                    for j, h in enumerate(holdings):
                        if h:
                            problem += f"{j}. {h}\n"

                    sample = {
                        'id': f"us_casehold_{i}",
                        'jurisdiction': 'US',
                        'problem': problem,
                        'problem_type': 'legal',
                        'task_type': 'case_prediction',
                        'source': 'casehold',
                        'ground_truth': {
                            'correct_index': label,
                            'correct_holding': holdings[label] if label < len(holdings) else ''
                        },
                        'legal_domain': 'civil',
                        'difficulty': 'hard'
                    }
                    samples.append(sample)

                except json.JSONDecodeError:
                    continue

        print(f"âœ… å¤„ç†å®Œæˆ: {len(samples)} æ ·æœ¬")

        if output_file:
            self._save_jsonl(samples, output_file)

        return samples

    def create_training_dataset(
        self,
        cn_samples: List[Dict],
        us_samples: List[Dict],
        output_file: str,
        cn_ratio: float = 0.5,
        task_type_ratios: Dict[str, float] = None
    ) -> List[Dict]:
        """
        åˆ›å»ºæ··åˆè®­ç»ƒæ•°æ®é›†

        Args:
            cn_samples: ä¸­å›½æ³•å¾‹æ ·æœ¬
            us_samples: ç¾å›½æ³•å¾‹æ ·æœ¬
            output_file: è¾“å‡ºæ–‡ä»¶
            cn_ratio: ä¸­å›½æ ·æœ¬æ¯”ä¾‹
            task_type_ratios: ä»»åŠ¡ç±»å‹æ¯”ä¾‹
        """
        task_type_ratios = task_type_ratios or {
            'case_prediction': 0.35,
            'statute_qa': 0.25,
            'consultation': 0.25,
            'document_gen': 0.15
        }

        # æŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„
        cn_by_task = defaultdict(list)
        us_by_task = defaultdict(list)

        for s in cn_samples:
            cn_by_task[s.get('task_type', 'consultation')].append(s)
        for s in us_samples:
            us_by_task[s.get('task_type', 'consultation')].append(s)

        # è®¡ç®—æ¯ç§ç±»å‹çš„æ ·æœ¬æ•°
        total_samples = len(cn_samples) + len(us_samples)
        cn_count = int(total_samples * cn_ratio)
        us_count = total_samples - cn_count

        final_samples = []

        # æŒ‰æ¯”ä¾‹é‡‡æ ·
        for task_type, ratio in task_type_ratios.items():
            cn_task_count = int(cn_count * ratio)
            us_task_count = int(us_count * ratio)

            cn_task_samples = cn_by_task.get(task_type, [])
            us_task_samples = us_by_task.get(task_type, [])

            if cn_task_samples:
                selected = random.sample(
                    cn_task_samples,
                    min(cn_task_count, len(cn_task_samples))
                )
                final_samples.extend(selected)

            if us_task_samples:
                selected = random.sample(
                    us_task_samples,
                    min(us_task_count, len(us_task_samples))
                )
                final_samples.extend(selected)

        # æ‰“ä¹±
        random.shuffle(final_samples)

        # ä¿å­˜
        self._save_jsonl(final_samples, output_file)

        # ç»Ÿè®¡
        stats = self._compute_stats(final_samples)
        print(f"\nğŸ“Š è®­ç»ƒæ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬: {len(final_samples)}")
        print(f"  CN: {stats['jurisdiction']['CN']}, US: {stats['jurisdiction']['US']}")
        print(f"  ä»»åŠ¡ç±»å‹åˆ†å¸ƒ: {stats['task_type']}")

        return final_samples

    def split_dataset(
        self,
        samples: List[Dict],
        train_ratio: float = 0.8,
        val_ratio: float = 0.1,
        output_dir: str = None
    ) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†"""
        random.shuffle(samples)

        n = len(samples)
        train_end = int(n * train_ratio)
        val_end = train_end + int(n * val_ratio)

        train = samples[:train_end]
        val = samples[train_end:val_end]
        test = samples[val_end:]

        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            self._save_jsonl(train, output_dir / "train.jsonl")
            self._save_jsonl(val, output_dir / "val.jsonl")
            self._save_jsonl(test, output_dir / "test.jsonl")

            print(f"\nğŸ’¾ æ•°æ®é›†å·²ä¿å­˜:")
            print(f"  è®­ç»ƒé›†: {len(train)} æ ·æœ¬")
            print(f"  éªŒè¯é›†: {len(val)} æ ·æœ¬")
            print(f"  æµ‹è¯•é›†: {len(test)} æ ·æœ¬")

        return train, val, test

    def _estimate_difficulty(self, item: Dict) -> str:
        """ä¼°è®¡æ ·æœ¬éš¾åº¦"""
        meta = item.get('meta', {})
        charges = meta.get('accusation', [])
        articles = meta.get('relevant_articles', [])

        # å¤šç½ªåæˆ–å¤šæ³•æ¡ -> å›°éš¾
        if len(charges) > 1 or len(articles) > 2:
            return 'hard'
        elif len(articles) > 1:
            return 'medium'
        else:
            return 'easy'

    def _detect_legal_domain(self, text: str, jurisdiction: str) -> str:
        """æ£€æµ‹æ³•å¾‹é¢†åŸŸ"""
        text_lower = text.lower()

        if jurisdiction == "CN":
            if any(kw in text for kw in ['åˆ‘æ³•', 'çŠ¯ç½ª', 'ç›—çªƒ', 'æ•…æ„', 'ç½ª']):
                return 'criminal'
            elif any(kw in text for kw in ['åˆåŒ', 'ä¹°å–', 'å€Ÿæ¬¾', 'å€ºåŠ¡']):
                return 'civil'
            elif any(kw in text for kw in ['è¡Œæ”¿', 'å¤„ç½š', 'è®¸å¯']):
                return 'administrative'
            elif any(kw in text for kw in ['åŠ³åŠ¨', 'å·¥èµ„', 'è§£é›‡', 'è¾é€€']):
                return 'labor'
        else:  # US
            if any(kw in text_lower for kw in ['criminal', 'crime', 'murder', 'theft', 'felony']):
                return 'criminal'
            elif any(kw in text_lower for kw in ['contract', 'agreement', 'breach']):
                return 'contract'
            elif any(kw in text_lower for kw in ['tort', 'negligence', 'injury', 'damages']):
                return 'tort'
            elif any(kw in text_lower for kw in ['constitution', 'amendment', 'rights']):
                return 'constitutional'

        return 'general'

    def _compute_stats(self, samples: List[Dict]) -> Dict:
        """è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'jurisdiction': defaultdict(int),
            'task_type': defaultdict(int),
            'legal_domain': defaultdict(int),
            'source': defaultdict(int),
            'difficulty': defaultdict(int)
        }

        for s in samples:
            stats['jurisdiction'][s.get('jurisdiction', 'unknown')] += 1
            stats['task_type'][s.get('task_type', 'unknown')] += 1
            stats['legal_domain'][s.get('legal_domain', 'unknown')] += 1
            stats['source'][s.get('source', 'unknown')] += 1
            stats['difficulty'][s.get('difficulty', 'unknown')] += 1

        return {k: dict(v) for k, v in stats.items()}

    def _save_jsonl(self, data: List[Dict], output_file: str):
        """ä¿å­˜ä¸ºJSONLæ ¼å¼"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"ğŸ’¾ ä¿å­˜: {output_path} ({len(data)} æ ·æœ¬)")


def test_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•æ³•å¾‹æ•°æ®å¤„ç†å™¨")
    print("="*60)

    processor = LegalDataProcessor(data_dir="data/legal")

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    cn_sample = {
        'id': 'cn_test_001',
        'jurisdiction': 'CN',
        'problem': 'è¢«å‘Šäººå¼ æŸç›—çªƒä»–äººè´¢ç‰©ä»·å€¼5000å…ƒï¼Œåº”å¦‚ä½•å®šç½ªé‡åˆ‘ï¼Ÿ',
        'problem_type': 'legal',
        'task_type': 'case_prediction',
        'source': 'test',
        'ground_truth': {'charges': ['ç›—çªƒç½ª'], 'articles': ['åˆ‘æ³•ç¬¬264æ¡']},
        'legal_domain': 'criminal',
        'difficulty': 'easy'
    }

    us_sample = {
        'id': 'us_test_001',
        'jurisdiction': 'US',
        'problem': 'Did the defendant breach the contract by failing to deliver goods?',
        'problem_type': 'legal',
        'task_type': 'statute_qa',
        'source': 'test',
        'ground_truth': {'answer': 'Yes, failure to deliver constitutes breach'},
        'legal_domain': 'contract',
        'difficulty': 'medium'
    }

    print(f"\nğŸ“‹ ç¤ºä¾‹CNæ ·æœ¬: {cn_sample['id']}")
    print(f"ğŸ“‹ ç¤ºä¾‹USæ ·æœ¬: {us_sample['id']}")


if __name__ == "__main__":
    test_processor()
