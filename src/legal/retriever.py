#!/usr/bin/env python3
"""
æ³•å¾‹æ£€ç´¢å™¨ - åŸºäºFAISSçš„å‘é‡æ£€ç´¢
Legal Retriever - FAISS-based vector search for CN/US legal systems

æ”¯æŒ:
- æ¡ˆä¾‹åº“æ£€ç´¢ (Case retrieval)
- æ³•æ¡åº“æ£€ç´¢ (Statute retrieval)
- ä¸­ç¾åˆ†ç¦»ç´¢å¼• (Separate indices for CN/US)
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Optional, Union
import numpy as np

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    print("âš ï¸  FAISS not installed. Run: pip install faiss-cpu")

try:
    from sentence_transformers import SentenceTransformer
    ST_AVAILABLE = True
except ImportError:
    ST_AVAILABLE = False
    print("âš ï¸  sentence-transformers not installed. Run: pip install sentence-transformers")


class LegalRetriever:
    """æ³•å¾‹æ£€ç´¢å™¨ - æ”¯æŒCN/USåŒç³»ç»Ÿ"""

    # é»˜è®¤åµŒå…¥æ¨¡å‹
    DEFAULT_EMBEDDING_MODELS = {
        'CN': 'shibing624/text2vec-base-chinese',  # ä¸­æ–‡æ¨¡å‹
        'US': 'all-MiniLM-L6-v2'  # è‹±æ–‡æ¨¡å‹
    }

    def __init__(
        self,
        data_dir: str = "data/legal",
        embedding_model_cn: str = None,
        embedding_model_us: str = None,
        device: str = "cpu"
    ):
        """
        Args:
            data_dir: æ³•å¾‹æ•°æ®ç›®å½•
            embedding_model_cn: ä¸­æ–‡åµŒå…¥æ¨¡å‹
            embedding_model_us: è‹±æ–‡åµŒå…¥æ¨¡å‹
            device: è®¡ç®—è®¾å¤‡
        """
        self.data_dir = Path(data_dir)
        self.device = device

        # åµŒå…¥æ¨¡å‹
        self.embedding_models = {}
        self.embedding_model_names = {
            'CN': embedding_model_cn or self.DEFAULT_EMBEDDING_MODELS['CN'],
            'US': embedding_model_us or self.DEFAULT_EMBEDDING_MODELS['US']
        }

        # FAISSç´¢å¼•
        self.case_indices = {'CN': None, 'US': None}
        self.statute_indices = {'CN': None, 'US': None}

        # åŸå§‹æ•°æ®
        self.cases = {'CN': [], 'US': []}
        self.statutes = {'CN': [], 'US': []}

        # ç´¢å¼•çŠ¶æ€
        self.initialized = {'CN': False, 'US': False}

    def _get_embedding_model(self, jurisdiction: str) -> 'SentenceTransformer':
        """è·å–æˆ–åŠ è½½åµŒå…¥æ¨¡å‹"""
        if not ST_AVAILABLE:
            raise RuntimeError("sentence-transformers not installed")

        if jurisdiction not in self.embedding_models:
            model_name = self.embedding_model_names[jurisdiction]
            print(f"ğŸ“¦ åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}")
            self.embedding_models[jurisdiction] = SentenceTransformer(
                model_name,
                device=self.device
            )

        return self.embedding_models[jurisdiction]

    def initialize(self, jurisdictions: List[str] = None):
        """åˆå§‹åŒ–æ£€ç´¢å™¨ - åŠ è½½æ•°æ®å’Œæ„å»ºç´¢å¼•"""
        if not FAISS_AVAILABLE:
            print("âŒ FAISS not available, retriever disabled")
            return

        jurisdictions = jurisdictions or ['CN', 'US']

        for jurisdiction in jurisdictions:
            if self.initialized[jurisdiction]:
                continue

            print(f"\n{'='*50}")
            print(f"ğŸ“š åˆå§‹åŒ– {jurisdiction} æ³•å¾‹æ£€ç´¢å™¨")
            print(f"{'='*50}")

            # åŠ è½½æ•°æ®
            self._load_cases(jurisdiction)
            self._load_statutes(jurisdiction)

            # æ„å»ºç´¢å¼•
            self._build_case_index(jurisdiction)
            self._build_statute_index(jurisdiction)

            self.initialized[jurisdiction] = True
            print(f"âœ… {jurisdiction} æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_cases(self, jurisdiction: str):
        """åŠ è½½æ¡ˆä¾‹æ•°æ®"""
        case_dir = self.data_dir / jurisdiction.lower() / "cases"

        if not case_dir.exists():
            print(f"âš ï¸  æ¡ˆä¾‹ç›®å½•ä¸å­˜åœ¨: {case_dir}")
            return

        for file_path in case_dir.glob("*.json*"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    if file_path.suffix == '.jsonl':
                        for line in f:
                            if line.strip():
                                self.cases[jurisdiction].append(json.loads(line))
                    else:
                        data = json.load(f)
                        if isinstance(data, list):
                            self.cases[jurisdiction].extend(data)
                        else:
                            self.cases[jurisdiction].append(data)
            except Exception as e:
                print(f"âŒ åŠ è½½æ¡ˆä¾‹æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        print(f"ğŸ“– åŠ è½½ {jurisdiction} æ¡ˆä¾‹: {len(self.cases[jurisdiction])} æ¡")

    def _load_statutes(self, jurisdiction: str):
        """åŠ è½½æ³•æ¡æ•°æ®"""
        statute_dir = self.data_dir / jurisdiction.lower() / "statutes"

        if not statute_dir.exists():
            print(f"âš ï¸  æ³•æ¡ç›®å½•ä¸å­˜åœ¨: {statute_dir}")
            return

        for file_path in statute_dir.glob("*.json*"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    if file_path.suffix == '.jsonl':
                        for line in f:
                            if line.strip():
                                self.statutes[jurisdiction].append(json.loads(line))
                    else:
                        data = json.load(f)
                        if isinstance(data, list):
                            self.statutes[jurisdiction].extend(data)
                        else:
                            self.statutes[jurisdiction].append(data)
            except Exception as e:
                print(f"âŒ åŠ è½½æ³•æ¡æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        print(f"ğŸ“œ åŠ è½½ {jurisdiction} æ³•æ¡: {len(self.statutes[jurisdiction])} æ¡")

    def _get_case_text(self, case: Dict, jurisdiction: str) -> str:
        """è·å–æ¡ˆä¾‹çš„æ–‡æœ¬è¡¨ç¤ºç”¨äºåµŒå…¥"""
        if jurisdiction == "CN":
            return f"{case.get('facts', '')} {case.get('reasoning', '')} {case.get('verdict', {})}"
        else:
            return f"{case.get('facts', '')} {case.get('holding', '')} {case.get('reasoning', '')}"

    def _get_statute_text(self, statute: Dict, jurisdiction: str) -> str:
        """è·å–æ³•æ¡çš„æ–‡æœ¬è¡¨ç¤ºç”¨äºåµŒå…¥"""
        if jurisdiction == "CN":
            base = f"{statute.get('law_name', '')} {statute.get('title', '')} {statute.get('content', '')}"
            # æ·»åŠ å¸æ³•è§£é‡Š
            interps = statute.get('interpretations', [])
            if interps:
                base += " " + " ".join([i.get('content', '') for i in interps[:2]])
            return base
        else:
            return f"{statute.get('code_name', '')} {statute.get('section_title', '')} {statute.get('content', '')}"

    def _build_case_index(self, jurisdiction: str):
        """æ„å»ºæ¡ˆä¾‹FAISSç´¢å¼•"""
        cases = self.cases[jurisdiction]
        if not cases:
            print(f"âš ï¸  æ—  {jurisdiction} æ¡ˆä¾‹æ•°æ®ï¼Œè·³è¿‡ç´¢å¼•æ„å»º")
            return

        print(f"ğŸ”¨ æ„å»º {jurisdiction} æ¡ˆä¾‹ç´¢å¼•...")

        # è·å–åµŒå…¥
        model = self._get_embedding_model(jurisdiction)
        texts = [self._get_case_text(c, jurisdiction) for c in cases]
        embeddings = model.encode(texts, show_progress_bar=True)

        # æ„å»ºFAISSç´¢å¼•
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)  # å†…ç§¯ç›¸ä¼¼åº¦

        # L2å½’ä¸€åŒ–åä½¿ç”¨å†…ç§¯ç­‰ä»·äºä½™å¼¦ç›¸ä¼¼åº¦
        faiss.normalize_L2(embeddings)
        index.add(embeddings.astype('float32'))

        self.case_indices[jurisdiction] = index
        print(f"âœ… {jurisdiction} æ¡ˆä¾‹ç´¢å¼•: {index.ntotal} å‘é‡, ç»´åº¦ {dimension}")

    def _build_statute_index(self, jurisdiction: str):
        """æ„å»ºæ³•æ¡FAISSç´¢å¼•"""
        statutes = self.statutes[jurisdiction]
        if not statutes:
            print(f"âš ï¸  æ—  {jurisdiction} æ³•æ¡æ•°æ®ï¼Œè·³è¿‡ç´¢å¼•æ„å»º")
            return

        print(f"ğŸ”¨ æ„å»º {jurisdiction} æ³•æ¡ç´¢å¼•...")

        model = self._get_embedding_model(jurisdiction)
        texts = [self._get_statute_text(s, jurisdiction) for s in statutes]
        embeddings = model.encode(texts, show_progress_bar=True)

        dimension = embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)

        faiss.normalize_L2(embeddings)
        index.add(embeddings.astype('float32'))

        self.statute_indices[jurisdiction] = index
        print(f"âœ… {jurisdiction} æ³•æ¡ç´¢å¼•: {index.ntotal} å‘é‡, ç»´åº¦ {dimension}")

    async def search_cases(
        self,
        query: str,
        jurisdiction: str = "CN",
        top_k: int = 3,
        legal_domain: str = None
    ) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³æ¡ˆä¾‹"""
        if not self.initialized.get(jurisdiction):
            print(f"âš ï¸  {jurisdiction} æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
            return []

        index = self.case_indices.get(jurisdiction)
        if index is None or index.ntotal == 0:
            return []

        # ç¼–ç æŸ¥è¯¢
        model = self._get_embedding_model(jurisdiction)
        query_embedding = model.encode([query])
        faiss.normalize_L2(query_embedding)

        # æœç´¢
        scores, indices = index.search(query_embedding.astype('float32'), top_k * 2)

        # è¿‡æ»¤å’Œæ’åº
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(self.cases[jurisdiction]):
                continue

            case = self.cases[jurisdiction][idx]

            # é¢†åŸŸè¿‡æ»¤
            if legal_domain:
                case_domain = case.get('legal_domain', '')
                if legal_domain.lower() not in case_domain.lower():
                    continue

            results.append({
                **case,
                'relevance_score': float(score)
            })

            if len(results) >= top_k:
                break

        return results

    async def search_statutes(
        self,
        query: str,
        jurisdiction: str = "CN",
        top_k: int = 5,
        legal_domain: str = None
    ) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³æ³•æ¡"""
        if not self.initialized.get(jurisdiction):
            print(f"âš ï¸  {jurisdiction} æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
            return []

        index = self.statute_indices.get(jurisdiction)
        if index is None or index.ntotal == 0:
            return []

        model = self._get_embedding_model(jurisdiction)
        query_embedding = model.encode([query])
        faiss.normalize_L2(query_embedding)

        scores, indices = index.search(query_embedding.astype('float32'), top_k * 2)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(self.statutes[jurisdiction]):
                continue

            statute = self.statutes[jurisdiction][idx]

            if legal_domain:
                statute_domain = statute.get('legal_domain', '')
                if legal_domain.lower() not in statute_domain.lower():
                    continue

            results.append({
                **statute,
                'relevance_score': float(score)
            })

            if len(results) >= top_k:
                break

        return results

    def save_indices(self, output_dir: str = None):
        """ä¿å­˜FAISSç´¢å¼•åˆ°ç£ç›˜"""
        output_dir = Path(output_dir or self.data_dir / "indices")
        output_dir.mkdir(parents=True, exist_ok=True)

        for jurisdiction in ['CN', 'US']:
            if self.case_indices[jurisdiction] and self.case_indices[jurisdiction].ntotal > 0:
                faiss.write_index(
                    self.case_indices[jurisdiction],
                    str(output_dir / f"{jurisdiction.lower()}_cases.index")
                )
                print(f"ğŸ’¾ ä¿å­˜ {jurisdiction} æ¡ˆä¾‹ç´¢å¼•")

            if self.statute_indices[jurisdiction] and self.statute_indices[jurisdiction].ntotal > 0:
                faiss.write_index(
                    self.statute_indices[jurisdiction],
                    str(output_dir / f"{jurisdiction.lower()}_statutes.index")
                )
                print(f"ğŸ’¾ ä¿å­˜ {jurisdiction} æ³•æ¡ç´¢å¼•")

    def load_indices(self, input_dir: str = None):
        """ä»ç£ç›˜åŠ è½½FAISSç´¢å¼•"""
        input_dir = Path(input_dir or self.data_dir / "indices")

        for jurisdiction in ['CN', 'US']:
            case_path = input_dir / f"{jurisdiction.lower()}_cases.index"
            statute_path = input_dir / f"{jurisdiction.lower()}_statutes.index"

            if case_path.exists():
                self.case_indices[jurisdiction] = faiss.read_index(str(case_path))
                print(f"ğŸ“‚ åŠ è½½ {jurisdiction} æ¡ˆä¾‹ç´¢å¼•: {self.case_indices[jurisdiction].ntotal} å‘é‡")

            if statute_path.exists():
                self.statute_indices[jurisdiction] = faiss.read_index(str(statute_path))
                print(f"ğŸ“‚ åŠ è½½ {jurisdiction} æ³•æ¡ç´¢å¼•: {self.statute_indices[jurisdiction].ntotal} å‘é‡")

    def get_stats(self) -> Dict:
        """è·å–æ£€ç´¢å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'CN': {
                'cases': len(self.cases['CN']),
                'statutes': len(self.statutes['CN']),
                'case_index_size': self.case_indices['CN'].ntotal if self.case_indices['CN'] else 0,
                'statute_index_size': self.statute_indices['CN'].ntotal if self.statute_indices['CN'] else 0,
                'initialized': self.initialized['CN']
            },
            'US': {
                'cases': len(self.cases['US']),
                'statutes': len(self.statutes['US']),
                'case_index_size': self.case_indices['US'].ntotal if self.case_indices['US'] else 0,
                'statute_index_size': self.statute_indices['US'].ntotal if self.statute_indices['US'] else 0,
                'initialized': self.initialized['US']
            }
        }


def test_retriever():
    """æµ‹è¯•æ£€ç´¢å™¨"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•æ³•å¾‹æ£€ç´¢å™¨")
    print("="*60)

    retriever = LegalRetriever(data_dir="data/legal")
    print(f"\næ£€ç´¢å™¨ç»Ÿè®¡: {retriever.get_stats()}")

    # å°è¯•åˆå§‹åŒ–ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
    # retriever.initialize(['CN'])


if __name__ == "__main__":
    test_retriever()
